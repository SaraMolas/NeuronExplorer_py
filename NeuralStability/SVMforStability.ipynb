{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to train a Support Vector Machine to classify sessions into low versus high neural stability based on several behavioural indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import packages\n",
    "\n",
    "from tkinter import filedialog\n",
    "import numpy as np \n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Choose directory and load data from each session\n",
    "# These 1-D vectors contain either the total number or the average number of each variable per session\n",
    "\n",
    "directory = filedialog.askdirectory()\n",
    "print(\"Selected directory:\", directory)\n",
    "numberLicks = np.load (directory + \"numberLicks.npy\")\n",
    "numberTrials = np.load (directory + \"numberTrials.npy\")\n",
    "pausingTime = np.load (directory + \"pausingTime.npy\")\n",
    "PCstab = np.load (directory + \"PCstability.npy\") \n",
    "preRewLicks = np.load (directory + \"preRewardLicks.npy\")\n",
    "preRewSlope = np.load (directory + \"preRewardSlope.npy\")\n",
    "licksC = np.load(directory + \"roomCLicks.npy\")\n",
    "speedC = np.load(directory + \"roomCspeed.npy\")\n",
    "speed = np.load(directory + \"runningSpeed.npy\")\n",
    "postRewLicks1Sec = np.load (directory + \"postRewardLicks1sec.npy\")\n",
    "postRewLicksHalfSec = np.load (directory + \"postRewardLicks3sec.npy\")\n",
    "postRewLicksQuarterSec = np.load (directory + \"postRewardLicks5sec.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train an SVM classifier testing different stability thresholds to find the cut-off point for optimal performance\n",
    "\n",
    "# 3.1. Prepare data for the SVM classifier and initialize output variable\n",
    "variables = np.column_stack((numberLicks, numberTrials, pausingTime, preRewLicks, preRewSlope, licksC, speedC, speed))\n",
    "stabilities = np.arange(0.2,0.8,0.1)\n",
    "features_names = ['numberLicks', 'numberTrials', 'pausingTime', 'preRewardLicks', 'preRewardSlope', 'licksRoomC', 'speedRoomC', 'speed']\n",
    "results = np.ndarray((len(stabilities),2))\n",
    "\n",
    "# 3.2. Iterate over all stability values \n",
    "for stab in stabilities: \n",
    "    # label sessions depending on whether their average stability score is above(1) or below(0) the designated stability threshold for this iteration\n",
    "    stabilityLabels = np.zeros((PCstab.shape[0],1)) \n",
    "    stabilityLabels[PCstab >= stab] = 1\n",
    "    \n",
    "    # train classifier using cross validation\n",
    "    clf = svm.SVC()\n",
    "    scores = cross_val_score(clf, variables, stabilityLabels.ravel(), cv=5)\n",
    "    results = np.vstack([results, np.array([[stab, scores.mean()]])]) # store the performance and stability threshold used\n",
    "    print(\"PC stability %0.2f gives %0.2f accuracy with a std of %0.2f\" % (stab, scores.mean(), scores.std()))\n",
    "\n",
    "if 'resultsData' in locals():\n",
    "    del resultsData\n",
    "resultsData = pd.DataFrame(results, columns = [\"Stability threshold\", \"Accuracy\"])   # convert the numpy array into a pandas dataframe\n",
    "\n",
    "# Plot a lineplot displaying the accuracy of the classifier at each stability threshold and save figure\n",
    "fig = plt.figure()\n",
    "a1 = fig.add_axes([0,0,1,1])\n",
    "a1.plot(resultsData[\"Stability threshold\"].values,  resultsData[\"Accuracy\"].values)\n",
    "a1.set_title('Accuracy of SVM classifier for different PC stability thresholds')\n",
    "a1.set_ylim(np.min(resultsData[\"Accuracy\"].values)-0.1, np.max(resultsData[\"Accuracy\"].values)+0.1)\n",
    "a1.set_xlim(np.min(resultsData[\"Stability threshold\"].values)-0.1, np.max(resultsData[\"Stability threshold\"].values)+0.1)\n",
    "a1.set_xlabel('PC stability threshold')\n",
    "a1.set_ylabel('Accuracy')\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "fig.set_size_inches(12, 6) # set figure's size manually \n",
    "\n",
    "directory_fig = filedialog.askdirectory()\n",
    "print(\"Selected directory for figure:\", directory_fig)\n",
    "plt.savefig(directory_fig + 'plot_SVMperformanceAcrossThresholds.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. After selecting the optimal stability threshold (in the case of my data the threshold selected is 0.5), increase SVM performance by hyperparameter tuning\n",
    "\n",
    "# 4.1. Establish variables and specify stability threshold used\n",
    "variables = np.column_stack((numberLicks, numberTrials, pausingTime, preRewLicks, preRewSlope, licksC, speedC, speed))\n",
    "stabilities = np.arange(0.2,0.8,0.1)\n",
    "features_names = ['numberLicks', 'numberTrials', 'pausingTime', 'preRewardLicks', 'preRewardSlope', 'licksRoomC', 'speedRoomC', 'speed']\n",
    "stabilityLabels = np.zeros((PCstab.shape[0],1))\n",
    "stab = 0.5 # threshold used will be 0.5, since that gave the best SVM performance\n",
    "stabilityLabels[PCstab >= stab] = 1 \n",
    "\n",
    "# 4.2. Preprocess variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(variables, stabilityLabels.ravel(), test_size = 0.30, random_state = 101) \n",
    "scaler = StandardScaler()\n",
    "X_trainScaled = scaler.fit(X_train).transform(X_train)\n",
    "X_testScaled = scaler.transform(X_test)\n",
    "\n",
    "# 4.3. Determine hyperparameter values used for the grid search\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}  \n",
    "\n",
    "# 4.4. Initialize classifier, perform grid search with crossvalidation and print the optimal hyperparameters for our dataset\n",
    "clf = svm.SVC()\n",
    "grid = GridSearchCV(clf, param_grid, refit = True, verbose = 3)   \n",
    "grid.fit(X_trainScaled, y_train)\n",
    "print(\"The best hyperparameters are: \", grid.best_params_) \n",
    "\n",
    "# 4.5. Now use the best hyperparameters to predict the output variable, in this case sessions with low(0) or high(1) stability, and print accuracy\n",
    "grid_predictions = grid.predict(X_testScaled) \n",
    "accuracy = accuracy_score(y_test, grid_predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
